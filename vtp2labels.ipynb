{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feat_matrix \n",
    "\n",
    "1. reduce the size of each feature matrix for each .vtp fiber bundle (basis of a percentage 10)\n",
    "2. attach label to each feat_matrix.h5 file using label mapping\n",
    "3. combine the 54 tracts mentioned in the supplementary of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['feat']>\n",
      "44656\n",
      "30\n",
      "10\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "2232\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "AF_left_feat_path = \"/media/ang/Data/unnerve_data/779370/779370_T_AF_left_featMatrix.h5\"\n",
    "\n",
    "# read feat_matrix\n",
    "with h5py.File(AF_left_feat_path, \"r\") as f:\n",
    "        # List all groups\n",
    "        print(\"Keys: %s\" % f.keys())\n",
    "        h_keys = list(f.keys())[0]\n",
    "\n",
    "        # Get the data\n",
    "        data = list(f[h_keys])\n",
    "        print(len(data))\n",
    "        print(len(f[h_keys][0]))\n",
    "\n",
    "        print(len(f[h_keys][0][0:10]))\n",
    "        print(type(f[h_keys]))\n",
    "        print(int(len(f[h_keys])/20))\n",
    "        compressed_data = f[h_keys][0: int(len(f[h_keys]))]\n",
    "        print(type(compressed_data))\n",
    "        \n",
    "\n",
    "# reduce the size of feature_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import h5py\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('S14')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping_72 = pd.read_csv(\"/home/ang/Documents/GitHub/DeepWMA/labels_reference.csv\", names=[\"label_names\", \"label_array\"])\n",
    "# label_mapping_54 =  pd.read_csv(\"/home/ang/Documents/GitHub/DeepWMA/labels_reference_54.csv\", names=[\"label_names\", \"label_array\"])\n",
    "\n",
    "label_mapping_72['label_array'].dtype\n",
    "label_mapping_72['label_names'] = label_mapping_72['label_names'].astype('|S')\n",
    "label_mapping_72['label_names'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_names</th>\n",
       "      <th>label_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'AF_left'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'AF_right'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'ATR_left'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'ATR_right'</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'CA'</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>b'T_PREF_right'</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>b'T_PREM_left'</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>b'T_PREM_right'</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>b'UF_left'</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>b'UF_right'</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label_names  label_array\n",
       "0        b'AF_left'            0\n",
       "1       b'AF_right'            1\n",
       "2       b'ATR_left'            2\n",
       "3      b'ATR_right'            3\n",
       "4             b'CA'            4\n",
       "..              ...          ...\n",
       "67  b'T_PREF_right'           67\n",
       "68   b'T_PREM_left'           68\n",
       "69  b'T_PREM_right'           69\n",
       "70       b'UF_left'           70\n",
       "71      b'UF_right'           71\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping_72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping_72.loc[label_mapping_72.label_names == bytes('T_PREF_right', 'utf-8'),'label_array'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF_left\n",
      "0\n",
      "AF_right\n",
      "1\n",
      "ATR_left\n",
      "2\n",
      "ATR_right\n",
      "3\n",
      "CA\n",
      "4\n",
      "CC_1\n",
      "5\n",
      "CC_2\n",
      "6\n",
      "CC_3\n",
      "7\n",
      "CC_4\n",
      "8\n",
      "CC_5\n",
      "9\n",
      "CC_6\n",
      "10\n",
      "CC_7\n",
      "11\n",
      "CC\n",
      "12\n",
      "CG_right\n",
      "14\n",
      "CST_left\n",
      "15\n",
      "CST_right\n",
      "16\n",
      "FPT_left\n",
      "17\n",
      "FPT_right\n",
      "18\n",
      "FX_left\n",
      "19\n",
      "FX_right\n",
      "20\n",
      "ICP_left\n",
      "21\n",
      "ICP_right\n",
      "22\n",
      "IFO_left\n",
      "23\n",
      "IFO_right\n",
      "24\n",
      "ILF_left\n",
      "25\n",
      "ILF_right\n",
      "26\n",
      "MLF_left\n",
      "28\n",
      "MLF_right\n",
      "29\n",
      "OR_left\n",
      "30\n",
      "OR_right\n",
      "31\n",
      "POPT_left\n",
      "32\n",
      "POPT_right\n",
      "33\n",
      "SCP_left\n",
      "34\n",
      "SCP_right\n",
      "35\n",
      "SLF_III_left\n",
      "36\n",
      "SLF_III_right\n",
      "37\n",
      "SLF_II_left\n",
      "38\n",
      "SLF_II_right\n",
      "39\n",
      "SLF_I_left\n",
      "40\n",
      "STR_left\n",
      "56\n",
      "STR_right\n",
      "57\n",
      "ST_FO_left\n",
      "42\n",
      "ST_FO_right\n",
      "43\n",
      "ST_OCC_left\n",
      "44\n",
      "ST_OCC_right\n",
      "45\n",
      "ST_PAR_left\n",
      "46\n",
      "ST_PAR_right\n",
      "47\n",
      "ST_POSTC_left\n",
      "48\n",
      "ST_POSTC_right\n",
      "49\n",
      "ST_PREC_left\n",
      "50\n",
      "ST_PREC_right\n",
      "51\n",
      "ST_PREF_left\n",
      "52\n",
      "CG_left\n",
      "13\n",
      "MCP\n",
      "27\n",
      "SLF_I_right\n",
      "41\n",
      "ST_PREF_right\n",
      "53\n",
      "ST_PREM_left\n",
      "54\n",
      "ST_PREM_right\n",
      "55\n",
      "T_OCC_left\n",
      "58\n",
      "T_OCC_right\n",
      "59\n",
      "T_PAR_left\n",
      "60\n",
      "T_PAR_right\n",
      "61\n",
      "T_POSTC_left\n",
      "62\n",
      "T_POSTC_right\n",
      "63\n",
      "T_PREC_left\n",
      "64\n",
      "T_PREC_right\n",
      "65\n",
      "T_PREF_left\n",
      "66\n",
      "T_PREF_right\n",
      "67\n",
      "T_PREM_left\n",
      "68\n",
      "T_PREM_right\n",
      "69\n",
      "UF_left\n",
      "70\n",
      "UF_right\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feat_array = np.random.random(size=(44656, 30, 30, 3))\n",
    "label_hdf_dtype = np.dtype([('label_names', str), ('label_values', int), ('label_array', int)])\n",
    "\n",
    "subject_ID=\"779370\"\n",
    "# pass this subject ID from the bash file code\n",
    "output_folder=\"/media/ang/Data/unnerve_data/\".format(subject_ID)\n",
    "fiber_tract='T_AF_LEFT'\n",
    "# either search for a list of names in the whole string path (find and replace type)\n",
    "\n",
    "feat_matrix= \"/media/ang/Data/unnerve_data/779370/779370_T_AF_left_featMatrix.h5\"\n",
    "\n",
    "for filename in os.listdir(\"/media/ang/Data/unnerve_data/779370/\"):\n",
    "    if filename.endswith((\".h5\")):\n",
    "        if \".vtk\" not in filename:\n",
    "            if \"atlas\" not in filename:\n",
    "                tract_name = filename.replace(subject_ID + \"_T_\", \"\").replace(\"_featMatrix.h5\", \"\")\n",
    "                print(tract_name)\n",
    "                print(label_mapping_72.loc[label_mapping_72.label_names == bytes(tract_name, 'utf-8'),'label_array'].item())\n",
    "\n",
    "    else: \n",
    "        continue\n",
    "        \n",
    "\n",
    "# with h5py.File('label_{}.h5'.format(fiber_tract),'w') as h5f:\n",
    "#     grp = h5f.create_group(fiber_tract)\n",
    "\n",
    "#     # iterate over all fiber tracts\n",
    "\n",
    "#     with h5py.File(feat_matrix, 'w') as feath5f: \n",
    "#         h_keys = list(feath5f.keys())[0]\n",
    "#         feath5f[h_keys]\n",
    "\n",
    "#         # limit the size of the numpy array to 5% of the array so that the error of big size can be resolved \n",
    "\n",
    "#         feat_label=np.empty(dtype=label_hdf_dtype, shape)\n",
    "\n",
    "#         # concatenate this feath5[h_keys] with a column of feat_matric.shape[0], so that values of label\n",
    "#         # can be assigned to each feat tract \n",
    "#         grp.create_dataset(fiber_tract, data=feath5f[h_keys])\n",
    "\n",
    "\n",
    "#         ## also create a separate label file for the size feat_matrix.shape[0]\n",
    "\n",
    "    \n",
    "#     # combine all fiber tract with 5% data \n",
    "#     # combine all labels (or keep appending the values)\n",
    "    \n",
    "#     h5f.create_dataset('label{}'.format, data=feat_label)\n",
    "\n",
    "# h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_array = np.random.random(size=(44656, 30, 30, 3))\n",
    "h5f = h5py.File('data.h5', 'w')\n",
    "\n",
    "label_hdf_dtype = np.dtype([('label_names', str), ('label_values', int), ('label_array', int)])\n",
    "\n",
    "subject_iD=\"779370\"\n",
    "# pass this subject ID from the bash file code\n",
    "output_folder=\"/media/ang/Data/unnerve_data/\".format(subject_ID)\n",
    "fiber_tract='T_AF_LEFT'\n",
    "# extract fiber tract name from the path of the tract\n",
    "# either search for a list of names in the whole string path (find and replace type)\n",
    "\n",
    "feat_matrix= \"/media/ang/Data/unnerve_data/779370/779370_T_AF_left_featMatrix.h5\"\n",
    "\n",
    "with h5py.File('label_{}.h5'.format(fiber_tract),'w') as h5f:\n",
    "    grp = h5f.create_group(fiber_tract)\n",
    "\n",
    "    # iterate over all fiber tracts\n",
    "\n",
    "    with h5py.File(feat_matrix, 'w') as feath5f: \n",
    "        h_keys = list(feath5f.keys())[0]\n",
    "        feath5f[h_keys]\n",
    "\n",
    "        # limit the size of the numpy array to 5% of the array so that the error of big size can be resolved \n",
    "\n",
    "        feat_label=np.empty(dtype=label_hdf_dtype, shape)\n",
    "\n",
    "        # concatenate this feath5[h_keys] with a column of feat_matric.shape[0], so that values of label\n",
    "        # can be assigned to each feat tract \n",
    "        grp.create_dataset(fiber_tract, data=feath5f[h_keys])\n",
    "\n",
    "\n",
    "        ## also create a separate label file for the size feat_matrix.shape[0]\n",
    "\n",
    "    \n",
    "    # combine all fiber tract with 5% data \n",
    "    # combine all labels (or keep appending the values)\n",
    "    \n",
    "    h5f.create_dataset('label{}'.format, data=feat_label)\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels\n",
    "\n",
    "1. after step 2 above\n",
    "2. combine the labels for each tract with limited fibers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('SupWMA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36aec90b5a07fafc043f146ab1db38cbda9ca0590150a6d49f81c4cf72882f5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
